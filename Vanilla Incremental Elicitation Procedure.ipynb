{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla Incremental Elicitation Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import des bibiliotéhques "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mip import Model, xsum, BINARY, minimize, maximize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Fonction M_Omega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour calculer le modèle de décision avec les poids\n",
    "def M_omega(x, omega):\n",
    "    return np.dot(x, omega)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calcule l'évaluation d'une solution 'x' avec un vecteur de poids 'omega'.\n",
    "    \n",
    "    Args:\n",
    "    - x (array-like): Vecteur représentant une solution avec ses scores pour chaque critère.\n",
    "    - omega (array-like): Vecteur représentant les poids associés à chaque critère.\n",
    "    \n",
    "    Returns:\n",
    "    - float: La somme pondérée des scores de 'x' selon les poids 'omega'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Fonction Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour poser une question au décideur\n",
    "def Query(x, y):\n",
    "    # Simule la préférence du décideur (choix aléatoire ici, à remplacer par une vraie préférence)\n",
    "    print(f\"Comparaison entre {x} et {y}\")\n",
    "    return x if np.random.rand() > 0.5 else y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Pose une question au décideur pour comparer deux solutions 'x' et 'y'.\n",
    "    La réponse est simulée par un choix aléatoire.\n",
    "    \n",
    "    Args:\n",
    "    - x (array-like): Première solution à comparer.\n",
    "    - y (array-like): Seconde solution à comparer.\n",
    "    \n",
    "    Returns:\n",
    "    - array-like: La solution préférée entre 'x' et 'y'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Résolution du probléme linéaire pour calculer PMR en utilisant MIP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction PMR calcule le regret maximum par paires entre deux solutions x et y, en tenant compte des poids admissibles définis dans \n",
    "Ω. Le regret est la différence entre les évaluations des deux solutions, maximisée pour le pire ensemble de poids possible dans le polytope Ω. \n",
    "\n",
    "- Modélisation du problème : On modélise cela comme un problème de programmation linéaire où on veut maximiser la différence entre l’évaluation de y et de x en fonction des poids w (qui sont les variables de décision dans le modèle).\n",
    "\n",
    "- On introduit une variable w pour chaque critère (chaque dimension du problème). Ces variables représentent les poids wi associés à chaque critère, qui doivent être trouvés pour maximiser le regret. Ces poids doivent respecter des contraintes de normalisation (somme égale à 1) et les autres contraintes définies dans Ω.\n",
    "\n",
    "- Ajout des contraintes de Ω: Ω est un polytope défini par un ensemble de contraintes linéaires. Chaque contrainte dans Ω a la forme d’une équation linéaire qui doit être respectée pour que les poids soient admissibles. Dans le code, on itère sur toutes les contraintes définies dans Ω et on les ajoute au modèle.\n",
    "\n",
    "-L’objectif est de maximiser la différence entre l'évaluation de y et x, c'est-à-dire maximiser Mw(y)-Mw(x), où Mw(.) est l’évaluation pondérée d’une solution par rapport aux poids w. Cela revient à maximiser la somme pondérée des différences entre y[i] et x[i]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Fonction PMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour calculer le regret maximum par paires en tenant compte des contraintes de m\n",
    "def PMR(x, y, m):  \n",
    "    m_crit = len(x)  # Nombre de critères\n",
    "\n",
    "    # Variables de décision : poids w_i pour chaque critère\n",
    "    w = [m.add_var(lb=0) for _ in range(m_crit)]\n",
    "    \n",
    "    # Contrainte : somme des poids w_i = 1 (normalisation des poids)\n",
    "    m += xsum(w[i] for i in range(m_crit)) == 1\n",
    "\n",
    "    # Objectif : maximiser M_omega(y) - M_omega(x)\n",
    "    m.objective = maximize(xsum(w[i] * (y[i] - x[i]) for i in range(m_crit)))\n",
    "    \n",
    "    # Résoudre le problème\n",
    "    m.optimize()\n",
    "    \n",
    "    # Obtenir le regret maximal (valeur de la fonction objectif)\n",
    "    return m.objective_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Calcule le regret maximum par paires (PMR) entre deux solutions 'x' et 'y'.\n",
    "    Utilise la programmation linéaire pour maximiser le regret sous les contraintes définies dans 'Omega'.\n",
    "    \n",
    "    Args:\n",
    "    - x (array-like): Première solution.\n",
    "    - y (array-like): Seconde solution.\n",
    "    - m (Model): Modèle MIP dans lequel les contraintes et l'objectif seront définis.\n",
    "    \n",
    "    Returns:\n",
    "    - float: La valeur du regret maximum entre 'x' et 'y', optimisée avec le modèle MIP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Fonction Update : Mise à jour du polytope Ω"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction Update a pour but de mettre à jour le polytope Ω, qui représente l'ensemble des poids possibles, en fonction des réponses du décideur à une question de préférence entre deux solutions x et y.\n",
    "\n",
    "- Décision du décideur : Le décideur est interrogé pour savoir s'il préfère x ou y. En fonction de sa réponse, on sait que le modèle de décision sous-jacent doit respecter certaines relations linéaires entre les poids w:\n",
    "    * Si x est préféré à y, cela signifie que la somme pondérée des critères pour x doit être plus grande ou égale à celle de y:         Mw(x) >= Mw(y).\n",
    "    * Sinon, l'inverse.\n",
    "\n",
    "- Ici, les coefficients de la contrainte sont la différence entre les vecteurs x et y. Le côté droit de l'inégalité est 0 car on compare directement les évaluations pondérées.\n",
    "\n",
    "- Mise à jour du polytope Ω : Une nouvelle contrainte est ajoutée au polytope Ω à chaque nouvelle réponse. Cette contrainte réduit l'espace des poids admissibles en excluant ceux qui ne respectent pas la préférence du décideur. Cette mise à jour affine la connaissance des préférences du décideur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour mettre à jour le polytope des poids possibles dans m\n",
    "def Update(m, answer, x, y):\n",
    "    # Créer une nouvelle contrainte basée sur la réponse du décideur\n",
    "    if np.array_equal(answer, x):\n",
    "        # x est préféré à y -> ajouter la contrainte M_omega(x) >= M_omega(y)\n",
    "        new_constraint = xsum((x[i] - y[i]) * m.var_by_name(f\"w[{i}]\") for i in range(len(x))) >= 0\n",
    "    else:\n",
    "        # y est préféré à x -> ajouter la contrainte M_omega(y) >= M_omega(x)\n",
    "        new_constraint = xsum((y[i] - x[i]) * m.var_by_name(f\"w[{i}]\") for i in range(len(x))) >= 0\n",
    "    \n",
    "    # Ajouter la nouvelle contrainte au modèle\n",
    "    m += new_constraint\n",
    "    \n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Met à jour le modèle MIP 'm' avec une nouvelle contrainte en fonction de la réponse du décideur.\n",
    "    Si 'x' est préféré à 'y', on ajoute une contrainte qui reflète cette préférence, et inversement.\n",
    "\n",
    "    Args:\n",
    "    - m (Model): Modèle MIP à mettre à jour.\n",
    "    - answer (array): L'alternative préférée par le décideur (résultat de la fonction 'Query').\n",
    "    - x (array): Première alternative comparée.\n",
    "    - y (array): Deuxième alternative comparée.\n",
    "\n",
    "    Returns:\n",
    "    - Model: Le modèle MIP mis à jour avec la nouvelle contrainte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour calculer le regret maximum (MR)\n",
    "def MR(x, X, m):\n",
    "    return max(PMR(x, y, m) for y in X if not np.array_equal(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "-  Calcule le regret maximum pour une alternative donnée 'x' par rapport à toutes les autres alternatives dans 'X'.\n",
    "\n",
    "    Args:\n",
    "    - x (array): L'alternative pour laquelle on veut calculer le regret.\n",
    "    - X (array of arrays): Ensemble d'alternatives à comparer avec 'x'.\n",
    "    - m (Model): Modèle MIP utilisé pour optimiser les regrets.\n",
    "\n",
    "    Returns:\n",
    "    - float: Le regret maximum pour 'x' par rapport aux autres alternatives dans 'X'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour calculer le regret minimax (mMR) et obtenir les solutions x_star et y_star\n",
    "def mMR(X, m):\n",
    "    x_star = min(X, key=lambda x: MR(x, X, m))\n",
    "    y_star = max(X, key=lambda y: PMR(x_star, y, m))\n",
    "    max_regret = MR(x_star, X, m)\n",
    "    return max_regret, x_star, y_star"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " - Calcule le regret minimax, c'est-à-dire l'alternative qui minimise son regret maximum par rapport aux autres.\n",
    "\n",
    "    Args:\n",
    "    - X (array of arrays): Ensemble d'alternatives.\n",
    "    - m (Model): Modèle MIP utilisé pour optimiser les regrets.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: (max_regret, x_star, y_star)\n",
    "        - max_regret (float): Le regret minimax pour 'x_star'.\n",
    "        - x_star (array): L'alternative qui minimise le regret maximum.\n",
    "        - y_star (array): L'alternative qui maximise le regret par rapport à 'x_star'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithme d'élucidation incrémentale vanilla\n",
    "def vanilla_incremental_elicitation(X, m, epsilon):\n",
    "    max_regret, x_star, y_star = mMR(X, m)\n",
    "    print(max_regret)\n",
    "    \n",
    "    while max_regret >= epsilon:\n",
    "        print(f\"Regret actuel: {max_regret}\")\n",
    "        print(f\"Question: préférez-vous {x_star} ou {y_star} ?\")\n",
    "        \n",
    "        # Poser la question au décideur\n",
    "        answer = Query(x_star, y_star)\n",
    "        \n",
    "        # Mettre à jour Omega en fonction de la réponse\n",
    "        Omega = Update(m, answer, x_star, y_star)\n",
    "        \n",
    "        # Recalculer le regret minimax\n",
    "        max_regret, x_star, y_star = mMR(X, m)\n",
    "    \n",
    "    return x_star"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Algorithme d'élucidation incrémentale vanilla. Cherche l'alternative optimale en minimisant le regret maximum\n",
    "    et en posant des questions au décideur jusqu'à ce que le regret soit inférieur à un seuil 'epsilon'.\n",
    "\n",
    "    Args:\n",
    "    - X (array of arrays): Ensemble d'alternatives à comparer.\n",
    "    - m (Model): Modèle MIP utilisé pour optimiser les regrets.\n",
    "    - epsilon (float): Seuil de regret maximal accepté pour arrêter l'algorithme.\n",
    "\n",
    "    Returns:\n",
    "    - array: L'alternative optimale 'x_star' trouvée à la fin de l'élucidation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple d'utilisation de l'élucidation\n",
    "def exemple_elicitation():\n",
    "    \"\"\"\n",
    "    Exemple d'utilisation de l'algorithme d'élucidation incrémentale.\n",
    "    Définit un ensemble de solutions et lance l'algorithme pour trouver la solution optimale.\n",
    "    \n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Ensemble des solutions (chaque solution a 2 critères)\n",
    "    X = np.array([[0.5, 0.2], [0.7, 0.1], [0.6, 0.3]])\n",
    "    \n",
    "    # Initialisation du modèle d'optimisation\n",
    "    m = Model()\n",
    "    \n",
    "    # Tolérance pour le regret minimax\n",
    "    epsilon = 0.1\n",
    "\n",
    "    # Lancer l'algorithme\n",
    "    solution = vanilla_incremental_elicitation(X, m, epsilon)\n",
    "\n",
    "    # Afficher la solution finale recommandée\n",
    "    print(f\"\\nSolution finale recommandée: {solution}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting solution of the Linear programming problem using Dual Simplex\n",
      "\n",
      "Coin0506I Presolve 0 (-1) rows, 0 (-2) columns and 0 (-2) elements\n",
      "Clp0000I Optimal - objective value 0.2\n",
      "Coin0511I After Postsolve, objective 0.2, infeasibilities - dual 0 (0), primal 0 (0)\n",
      "Clp0032I Optimal objective 0.2 - 0 iterations time 0.002, Presolve 0.00\n",
      "Starting solution of the Linear programming problem using Dual Simplex\n",
      "\n",
      "Clp0006I 0  Obj -0 Primal inf 0.999999 (1) Dual inf 2e+10 (2)\n",
      "Clp0000I Optimal - objective value 0.1\n",
      "Starting solution of the Linear programming problem using Dual Simplex\n",
      "\n",
      "Clp0006I 0  Obj -0 Primal inf 0.999999 (1) Dual inf 2e+10 (2)\n",
      "Clp0000I Optimal - objective value 0.1\n",
      "Starting solution of the Linear programming problem using Dual Simplex\n",
      "\n",
      "Clp0006I 0  Obj -0 Primal inf 0.999999 (1) Dual inf 2e+10 (2)\n",
      "Clp0000I Optimal - objective value 0.2\n",
      "Starting solution of the Linear programming problem using Dual Simplex\n",
      "\n",
      "Clp0006I 0  Obj -0 Primal inf 0.999999 (1) Dual inf 2e+10 (2)\n",
      "Clp0000I Optimal - objective value -0.1\n",
      "Starting solution of the Linear programming problem using Dual Simplex\n",
      "\n",
      "Clp0006I 0  Obj -0 Primal inf 0.999999 (1) Dual inf 2e+10 (2)\n",
      "Clp0000I Optimal - objective value 0.1\n",
      "Starting solution of the Linear programming problem using Dual Simplex\n",
      "\n",
      "Clp0006I 0  Obj -0 Primal inf 0.999999 (1) Dual inf 2e+10 (2)\n",
      "Clp0000I Optimal - objective value -0.1\n",
      "Starting solution of the Linear programming problem using Dual Simplex\n",
      "\n",
      "Clp0006I 0  Obj -0 Primal inf 0.999999 (1) Dual inf 2e+10 (2)\n",
      "Clp0000I Optimal - objective value 0.1\n",
      "Starting solution of the Linear programming problem using Dual Simplex\n",
      "\n",
      "Clp0006I 0  Obj -0 Primal inf 0.999999 (1) Dual inf 1.999998 (2)\n",
      "Clp0000I Optimal - objective value 0\n",
      "Starting solution of the Linear programming problem using Dual Simplex\n",
      "\n",
      "Clp0006I 0  Obj -0 Primal inf 0.999999 (1) Dual inf 2e+10 (2)\n",
      "Clp0000I Optimal - objective value -0.1\n",
      "Starting solution of the Linear programming problem using Dual Simplex\n",
      "\n",
      "Clp0006I 0  Obj -0 Primal inf 0.999999 (1) Dual inf 2e+10 (2)\n",
      "Clp0000I Optimal - objective value 0.1\n",
      "0.09999999999999998\n",
      "\n",
      "Solution finale recommandée: [0.6 0.3]\n"
     ]
    }
   ],
   "source": [
    "# Lancer l'exemple\n",
    "exemple_elicitation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
