{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla Incremental Elicitation Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mip import Model, xsum, BINARY, minimize, maximize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour calculer le modèle de décision avec les poids\n",
    "def M_omega(x, omega):\n",
    "    return np.dot(x, omega)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calcule l'évaluation d'une solution 'x' avec un vecteur de poids 'omega'.\n",
    "    \n",
    "    Args:\n",
    "    - x (array-like): Vecteur représentant une solution avec ses scores pour chaque critère.\n",
    "    - omega (array-like): Vecteur représentant les poids associés à chaque critère.\n",
    "    \n",
    "    Returns:\n",
    "    - float: La somme pondérée des scores de 'x' selon les poids 'omega'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour poser une question au décideur\n",
    "def Query(x, y):\n",
    "    # Simule la préférence du décideur (choix aléatoire ici, à remplacer par une vraie préférence)\n",
    "    print(f\"Comparaison entre {x} et {y}\")\n",
    "    return x if np.random.rand() > 0.5 else y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Pose une question au décideur pour comparer deux solutions 'x' et 'y'.\n",
    "    La réponse est simulée par un choix aléatoire.\n",
    "    \n",
    "    Args:\n",
    "    - x (array-like): Première solution à comparer.\n",
    "    - y (array-like): Seconde solution à comparer.\n",
    "    \n",
    "    Returns:\n",
    "    - array-like: La solution préférée entre 'x' et 'y'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Résolution du probléme linéaire pour calculer PMR en utilisant MIP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction PMR calcule le regret maximum par paires entre deux solutions x et y, en tenant compte des poids admissibles définis dans \n",
    "Ω. Le regret est la différence entre les évaluations des deux solutions, maximisée pour le pire ensemble de poids possible dans le polytope Ω. \n",
    "\n",
    "- Modélisation du problème : On modélise cela comme un problème de programmation linéaire où on veut maximiser la différence entre l’évaluation de y et de x en fonction des poids w (qui sont les variables de décision dans le modèle).\n",
    "\n",
    "- On introduit une variable w pour chaque critère (chaque dimension du problème). Ces variables représentent les poids wi associés à chaque critère, qui doivent être trouvés pour maximiser le regret. Ces poids doivent respecter des contraintes de normalisation (somme égale à 1) et les autres contraintes définies dans Ω.\n",
    "\n",
    "- Ajout des contraintes de Ω: Ω est un polytope défini par un ensemble de contraintes linéaires. Chaque contrainte dans Ω a la forme d’une équation linéaire qui doit être respectée pour que les poids soient admissibles. Dans le code, on itère sur toutes les contraintes définies dans Ω et on les ajoute au modèle.\n",
    "\n",
    "-L’objectif est de maximiser la différence entre l'évaluation de y et x, c'est-à-dire maximiser Mw(y)-Mw(x), où Mw(.) est l’évaluation pondérée d’une solution par rapport aux poids w. Cela revient à maximiser la somme pondérée des différences entre y[i] et x[i]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour calculer le regret maximum par paires en tenant compte des contraintes de Omega\n",
    "def PMR(x, y, Omega):\n",
    "    # Créer un modèle mip pour résoudre le problème linéaire\n",
    "    m = Model(sense=maximize)\n",
    "    \n",
    "    m_crit = len(x)  # Nombre de critères\n",
    "    \n",
    "    # Variables de décision : poids w_i pour chaque critère\n",
    "    w = [m.add_var(lb=0) for _ in range(m_crit)]\n",
    "    \n",
    "    # Contrainte : somme des poids w_i = 1 (normalisation des poids)\n",
    "    m += xsum(w[i] for i in range(m_crit)) == 1\n",
    "    \n",
    "    # Contrainte : ajouter les contraintes définies par le polytope Omega\n",
    "    for constraint in Omega:\n",
    "        m += xsum(w[i] * constraint['coefficients'][i] for i in range(m_crit)) >= constraint['rhs'] #la somme pondérée des variables \n",
    "                                                                                                     #de décision wi\n",
    "    \n",
    "    # Objectif : maximiser M_omega(y) - M_omega(x)\n",
    "    m.objective = xsum(w[i] * (y[i] - x[i]) for i in range(m_crit))\n",
    "    \n",
    "    # Résoudre le problème\n",
    "    m.optimize()\n",
    "    \n",
    "    # Obtenir le regret maximal\n",
    "    return m.objective_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Calcule le regret maximum par paires (PMR) entre deux solutions 'x' et 'y'.\n",
    "    Utilise la programmation linéaire pour maximiser le regret sous les contraintes définies dans 'Omega'.\n",
    "    \n",
    "    Args:\n",
    "    - x (array-like): Première solution.\n",
    "    - y (array-like): Seconde solution.\n",
    "    - Omega (list): Polytope des poids admissibles défini par un ensemble de contraintes.\n",
    "    \n",
    "    Returns:\n",
    "    - float: La valeur du regret maximum pour la paire (x, y)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction Update : Mise à jour du polytope Ω"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction Update a pour but de mettre à jour le polytope Ω, qui représente l'ensemble des poids possibles, en fonction des réponses du décideur à une question de préférence entre deux solutions x et y.\n",
    "\n",
    "- Décision du décideur : Le décideur est interrogé pour savoir s'il préfère x ou y. En fonction de sa réponse, on sait que le modèle de décision sous-jacent doit respecter certaines relations linéaires entre les poids w:\n",
    "    * Si x est préféré à y, cela signifie que la somme pondérée des critères pour x doit être plus grande ou égale à celle de y:         Mw(x) >= Mw(y).\n",
    "    * Sinon, l'inverse.\n",
    "\n",
    "- Ici, les coefficients de la contrainte sont la différence entre les vecteurs x et y. Le côté droit de l'inégalité est 0 car on compare directement les évaluations pondérées.\n",
    "\n",
    "- Mise à jour du polytope Ω : Une nouvelle contrainte est ajoutée au polytope Ω à chaque nouvelle réponse. Cette contrainte réduit l'espace des poids admissibles en excluant ceux qui ne respectent pas la préférence du décideur. Cette mise à jour affine la connaissance des préférences du décideur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour mettre à jour le polytope des poids possibles Omega\n",
    "def Update(Omega, answer, x, y):\n",
    "    new_constraint = {}\n",
    "    if np.array_equal(answer, x):\n",
    "        # x est préféré à y -> ajouter la contrainte M_omega(x) >= M_omega(y)\n",
    "        new_constraint['coefficients'] = x - y\n",
    "        new_constraint['rhs'] = 0\n",
    "    else:\n",
    "        # y est préféré à x -> ajouter la contrainte M_omega(y) >= M_omega(x)\n",
    "        new_constraint['coefficients'] = y - x\n",
    "        new_constraint['rhs'] = 0\n",
    "    \n",
    "    # Mettre à jour le polytope Omega en ajoutant la nouvelle contrainte\n",
    "    Omega.append(new_constraint)\n",
    "    \n",
    "    return Omega"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Met à jour le polytope des poids admissibles 'Omega' en ajoutant une nouvelle contrainte\n",
    "    basée sur la réponse du décideur. Si 'x' est préféré à 'y', on ajoute la contrainte M_omega(x) >= M_omega(y).\n",
    "    \n",
    "    Args:\n",
    "    - Omega (list): Polytope des poids admissibles représenté sous forme de contraintes.\n",
    "    - answer (array-like): La solution préférée (soit 'x' soit 'y').\n",
    "    - x (array-like): Première solution.\n",
    "    - y (array-like): Seconde solution.\n",
    "    \n",
    "    Returns:\n",
    "    - list: Le polytope 'Omega' mis à jour avec la nouvelle contrainte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour calculer le regret maximum (MR)\n",
    "def MR(x, X, Omega):\n",
    "    return max(PMR(x, y, Omega) for y in X if not np.array_equal(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calcule le regret maximum d'une solution 'x' par rapport à toutes les autres solutions dans 'X'.\n",
    "    \n",
    "    Args:\n",
    "    - x (array-like): Solution pour laquelle on calcule le regret.\n",
    "    - X (array-like): Ensemble des solutions.\n",
    "    - Omega (list): Polytope des poids admissibles.\n",
    "    \n",
    "    Returns:\n",
    "    - float: Le regret maximum pour la solution 'x'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour calculer le regret minimax (mMR) et obtenir les solutions x_star et y_star\n",
    "def mMR(X, Omega):\n",
    "    x_star = min(X, key=lambda x: MR(x, X, Omega))\n",
    "    y_star = max(X, key=lambda y: PMR(x_star, y, Omega))\n",
    "    max_regret = MR(x_star, X, Omega)\n",
    "    return max_regret, x_star, y_star"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calcule le regret minimax parmi un ensemble de solutions 'X'.\n",
    "    Trouve la solution 'x_star' qui minimise le regret maximum et la solution 'y_star' qui maximise le regret.\n",
    "    \n",
    "    Args:\n",
    "    - X (array-like): Ensemble des solutions à comparer.\n",
    "    - Omega (list): Polytope des poids admissibles défini par des contraintes.\n",
    "    \n",
    "    Returns:\n",
    "    - tuple: (regret_minimax, x_star, y_star) où:\n",
    "        - regret_minimax (float): La valeur du regret minimax.\n",
    "        - x_star (array-like): La solution minimisant le regret.\n",
    "        - y_star (array-like): La solution maximisant le regret par rapport à 'x_star'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithme d'élucidation incrémentale vanilla\n",
    "def vanilla_incremental_elicitation(X, Omega, epsilon):\n",
    "    max_regret, x_star, y_star = mMR(X, Omega)\n",
    "    \n",
    "    while max_regret >= epsilon:\n",
    "        print(f\"Regret actuel: {max_regret}\")\n",
    "        print(f\"Question: préférez-vous {x_star} ou {y_star} ?\")\n",
    "        \n",
    "        # Poser la question au décideur\n",
    "        answer = Query(x_star, y_star)\n",
    "        \n",
    "        # Mettre à jour Omega en fonction de la réponse\n",
    "        Omega = Update(Omega, answer, x_star, y_star)\n",
    "        \n",
    "        # Recalculer le regret minimax\n",
    "        max_regret, x_star, y_star = mMR(X, Omega)\n",
    "    \n",
    "    return x_star"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Implémente l'algorithme d'élucidation incrémentale pour minimiser le regret minimax.\n",
    "    Pose des questions au décideur pour affiner ses préférences jusqu'à ce que le regret minimax soit inférieur à 'epsilon'.\n",
    "    \n",
    "    Args:\n",
    "    - X (array-like): Ensemble des solutions disponibles.\n",
    "    - Omega (list): Polytope des poids admissibles sous forme de contraintes linéaires.\n",
    "    - epsilon (float): Seuil de tolérance pour le regret minimax.\n",
    "    \n",
    "    Returns:\n",
    "    - array-like: La solution finale 'x_star' recommandée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple d'utilisation de l'élucidation\n",
    "def exemple_elicitation():\n",
    "    X = np.array([[0.5, 0.2], [0.7, 0.1], [0.6, 0.3]])\n",
    "    \n",
    "    # Polytope initial : normalisation des poids\n",
    "    Omega = [{'coefficients': [1, 1], 'rhs': 1}]  # Initialisation d'un simple polytope\n",
    "\n",
    "    epsilon = 0.1\n",
    "\n",
    "    solution = vanilla_incremental_elicitation(X, Omega, epsilon)\n",
    "\n",
    "    print(f\"\\nSolution finale recommandée: {solution}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the CBC MILP Solver \n",
      "Version: Trunk\n",
      "Build Date: Oct 28 2021 \n",
      "\n",
      "Starting solution of the Linear programming problem using Dual Simplex\n",
      "\n",
      "Coin0506I Presolve 0 (-2) rows, 0 (-2) columns and 0 (-4) elements\n",
      "Clp0000I Optimal - objective value -0.1\n",
      "Coin0511I After Postsolve, objective -0.1, infeasibilities - dual 0 (0), primal 0 (0)\n",
      "Clp0032I Optimal objective -0.1 - 0 iterations time 0.002, Presolve 0.00\n",
      "Starting solution of the Linear programming problem using Dual Simplex\n",
      "\n",
      "Coin0506I Presolve 0 (-2) rows, 0 (-2) columns and 0 (-4) elements\n",
      "Clp0000I Optimal - objective value 0.1\n",
      "Coin0511I After Postsolve, objective 0.1, infeasibilities - dual 0 (0), primal 0 (0)\n",
      "Clp0032I Optimal objective 0.1 - 0 iterations time 0.002, Presolve 0.00\n",
      "Starting solution of the Linear programming problem using Dual Simplex\n",
      "\n",
      "Coin0506I Presolve 0 (-2) rows, 0 (-2) columns and 0 (-4) elements\n",
      "Clp0000I Optimal - objective value -0.2\n",
      "Coin0511I After Postsolve, objective -0.2, infeasibilities - dual 0 (0), primal 0 (0)\n",
      "Clp0032I Optimal objective -0.2 - 0 iterations time 0.002, Presolve 0.00\n",
      "Starting solution of the Linear programming problem using Dual Simplex\n",
      "\n",
      "Coin0506I Presolve 0 (-2) rows, 0 (-2) columns and 0 (-4) elements\n",
      "Clp0000I Optimal - objective value -0.1\n",
      "Coin0511I After Postsolve, objective -0.1, infeasibilities - dual 0 (0), primal 0 (0)\n",
      "Clp0032I Optimal objective -0.1 - 0 iterations time 0.002, Presolve 0.00\n",
      "Starting solution of the Linear programming problem using Dual Simplex\n",
      "\n",
      "Coin0506I Presolve 0 (-2) rows, 0 (-2) columns and 0 (-4) elements\n",
      "Clp0000I Optimal - objective value -0.1\n",
      "Coin0511I After Postsolve, objective -0.1, infeasibilities - dual 0 (0), primal 0 (0)\n",
      "Clp0032I Optimal objective -0.1 - 0 iterations time 0.002, Presolve 0.00\n",
      "Starting solution of the Linear programming problem using Dual Simplex\n",
      "\n",
      "Coin0506I Presolve 0 (-2) rows, 0 (-2) columns and 0 (-4) elements\n",
      "Clp0000I Optimal - objective value -0.2\n",
      "Coin0511I After Postsolve, objective -0.2, infeasibilities - dual 0 (0), primal 0 (0)\n",
      "Clp0032I Optimal objective -0.2 - 0 iterations time 0.002, Presolve 0.00\n",
      "Starting solution of the Linear programming problem using Dual Simplex\n",
      "\n",
      "Coin0506I Presolve 0 (-2) rows, 0 (-2) columns and 0 (-4) elements\n",
      "Clp0000I Optimal - objective value -0.2\n",
      "Coin0511I After Postsolve, objective -0.2, infeasibilities - dual 0 (0), primal 0 (0)\n",
      "Clp0032I Optimal objective -0.2 - 0 iterations time 0.002, Presolve 0.00\n",
      "Starting solution of the Linear programming problem using Dual Simplex\n",
      "\n",
      "Coin0506I Presolve 0 (-2) rows, 0 (-2) columns and 0 (-4) elements\n",
      "Clp0000I Optimal - objective value 0\n",
      "Coin0511I After Postsolve, objective 0, infeasibilities - dual 0 (0), primal 0 (0)\n",
      "Clp0032I Optimal objective 0 - 0 iterations time 0.002, Presolve 0.00\n",
      "Starting solution of the Linear programming problem using Dual Simplex\n",
      "\n",
      "Coin0506I Presolve 0 (-2) rows, 0 (-2) columns and 0 (-4) elements\n",
      "Clp0000I Optimal - objective value -0.1\n",
      "Coin0511I After Postsolve, objective -0.1, infeasibilities - dual 0 (0), primal 0 (0)\n",
      "Clp0032I Optimal objective -0.1 - 0 iterations time 0.002, Presolve 0.00\n",
      "Starting solution of the Linear programming problem using Dual Simplex\n",
      "\n",
      "Coin0506I Presolve 0 (-2) rows, 0 (-2) columns and 0 (-4) elements\n",
      "Clp0000I Optimal - objective value -0.2\n",
      "Coin0511I After Postsolve, objective -0.2, infeasibilities - dual 0 (0), primal 0 (0)\n",
      "Clp0032I Optimal objective -0.2 - 0 iterations time 0.002, Presolve 0.00\n",
      "Starting solution of the Linear programming problem using Dual Simplex\n",
      "\n",
      "Coin0506I Presolve 0 (-2) rows, 0 (-2) columns and 0 (-4) elements\n",
      "Clp0000I Optimal - objective value -0.1\n",
      "Coin0511I After Postsolve, objective -0.1, infeasibilities - dual 0 (0), primal 0 (0)\n",
      "Clp0032I Optimal objective -0.1 - 0 iterations time 0.002, Presolve 0.00\n",
      "\n",
      "Solution finale recommandée: [0.7 0.1]\n"
     ]
    }
   ],
   "source": [
    "# Lancer l'exemple\n",
    "exemple_elicitation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
